{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged = pd.read_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5118729190476188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Group the data by Inflation and by date\n",
    "a = merged.copy()\n",
    "a = a[a['date']>'2012']\n",
    "grouped = a.groupby(['Inflation', 'date'])\n",
    "total_returns = []\n",
    "\n",
    "# Iterate through the grouped data and select the top 10 and bottom 10 industries by return\n",
    "for name, group in grouped:\n",
    "    inflation, date = name\n",
    "    sorted_group = group.sort_values(\"MthRet\", ascending=False)\n",
    "    top_10 = sorted_group.head(10)\n",
    "    bottom_10 = sorted_group.tail(10)\n",
    "    top_10_return = np.mean(top_10[\"MthRet\"])\n",
    "    bottom_10_return = np.mean(bottom_10[\"MthRet\"])\n",
    "    total_return = top_10_return - bottom_10_return\n",
    "    total_returns.append(total_return)\n",
    "    #Ignore this, this was just so I could check some of the stuff\n",
    "    #print(\"Date: {}, Inflation: {}\\nTop 10 Industries by Return: {}\\nBottom 10 Industries by Return: {}\\nTotal Return: {}\\n\".format(date, inflation, top_10_return, bottom_10_return, total_return))\n",
    "\n",
    "total_returns = [x for x in total_returns if not np.isnan(x)]\n",
    "average_total_return = np.mean(total_returns)\n",
    "\n",
    "average_total_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Group the data by date and get the monthly return for each industry\n",
    "grouped_by_date = a.groupby(\"MthCalDt\")\n",
    "\n",
    "# Create an empty list to store the weighted monthly return for the top 10% of industries for each date\n",
    "monthly_return_top_10_percent_weighted = []\n",
    "\n",
    "# Iterate through each date group\n",
    "for date, date_group in grouped_by_date:\n",
    "    # Sort the date group by monthly return\n",
    "    date_group_sorted = date_group.sort_values(\"MthRet\", ascending=False)\n",
    "    \n",
    "    # Get the number of industries for this date group\n",
    "    n = len(date_group_sorted)\n",
    "    \n",
    "    # Get the top 10% of industries\n",
    "    top_10_percent = date_group_sorted.iloc[:int(n * 0.1)]\n",
    "    \n",
    "    # Calculate the weighted monthly return for the top 10% of industries\n",
    "    weighted_monthly_return = (top_10_percent[\"MthRet\"] * top_10_percent[\"ShrOut\"]).sum() / top_10_percent[\"ShrOut\"].sum()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    monthly_return_top_10_percent_weighted.append((date, weighted_monthly_return))\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "monthly_return_top_10_percent_weighted_df = pd.DataFrame(monthly_return_top_10_percent_weighted, columns=[\"MthCalDt\", \"Weighted_Avg_Monthly_Return\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry Title                                    Inflation\n",
       "BIOLOGICAL PRODUCTS, (NO DISGNOSTIC SUBSTANCES)   deflation   -0.000049\n",
       "                                                  low          0.005287\n",
       "                                                  mid          0.017790\n",
       "                                                  high         0.030621\n",
       "BOTTLED & CANNED SOFT DRINKS & CARBONATED WATERS  deflation    0.012558\n",
       "                                                                 ...   \n",
       "TELEPHONE COMMUNICATIONS (NO RADIOTELEPHONE)      high         0.012059\n",
       "TRUCKING (NO LOCAL)                               deflation    0.019999\n",
       "                                                  low          0.008438\n",
       "                                                  mid          0.014196\n",
       "                                                  high         0.004208\n",
       "Name: MthRet, Length: 232, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Industry_Inflation_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5118729190476188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Group the data by Inflation and by date\n",
    "a = merged.copy()\n",
    "a = a[a['date']>'2012']\n",
    "grouped = a.groupby(['Inflation', 'date'])\n",
    "total_returns = []\n",
    "\n",
    "# Iterate through the grouped data and select the top 10 and bottom 10 industries by return\n",
    "for name, group in grouped:\n",
    "    inflation, date = name\n",
    "    sorted_group = group.sort_values(\"MthRet\", ascending=False)\n",
    "    top_10 = sorted_group.head(10)\n",
    "    bottom_10 = sorted_group.tail(10)\n",
    "    top_10_return = np.mean(top_10[\"MthRet\"])\n",
    "    bottom_10_return = np.mean(bottom_10[\"MthRet\"])\n",
    "    total_return = top_10_return - bottom_10_return\n",
    "    total_returns.append(total_return)\n",
    "    #Ignore this, this was just so I could check some of the stuff\n",
    "    #print(\"Date: {}, Inflation: {}\\nTop 10 Industries by Return: {}\\nBottom 10 Industries by Return: {}\\nTotal Return: {}\\n\".format(date, inflation, top_10_return, bottom_10_return, total_return))\n",
    "\n",
    "total_returns = [x for x in total_returns if not np.isnan(x)]\n",
    "average_total_return = np.mean(total_returns)\n",
    "\n",
    "average_total_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001315082076721943"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Group the data by Inflation and by date\n",
    "a = merged.copy()\n",
    "a = a[a['date']>'1947']\n",
    "grouped = a.groupby(['Inflation', 'date'])\n",
    "total_returns = []\n",
    "\n",
    "# Calculate the top 10 and bottom 10 industries for each inflation category over the entire duration\n",
    "top_industries = {}\n",
    "bottom_industries = {}\n",
    "for inflation in a['Inflation'].unique():\n",
    "    if pd.isna(inflation):\n",
    "        continue\n",
    "    inflation_group = a[a['Inflation']==inflation]\n",
    "    sorted_group = inflation_group.sort_values(\"MthRet\", ascending=False)\n",
    "    top_10 = list(sorted_group.head(1000)['Industry Title'].unique())\n",
    "    bottom_10 = list(sorted_group[sorted_group[\"MthRet\"] < 0]['Industry Title'].unique()[:1000])\n",
    "    top_industries[inflation] = top_10\n",
    "    bottom_industries[inflation] = bottom_10\n",
    "\n",
    "# Iterate through the grouped data and calculate the average return for each date\n",
    "for name, group in grouped:\n",
    "    date = name[1]\n",
    "    inflation = group['Inflation'].iloc[0]\n",
    "    if pd.isna(inflation):\n",
    "        continue\n",
    "    top_10_industries = top_industries[inflation]\n",
    "    bottom_10_industries = bottom_industries[inflation]\n",
    "    top_10 = group[group['Industry Title'].isin(top_10_industries)]\n",
    "    bottom_10 = group[group['Industry Title'].isin(bottom_10_industries)]\n",
    "    top_10_return = np.mean(top_10[\"MthRet\"])\n",
    "    bottom_10_return = np.mean(bottom_10[\"MthRet\"])\n",
    "    total_return = top_10_return - bottom_10_return\n",
    "    total_returns.append(total_return)\n",
    "\n",
    "\n",
    "total_returns = [x for x in total_returns if not np.isnan(x)]\n",
    "average_total_return = np.mean(total_returns)\n",
    "\n",
    "average_total_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[103], line 28\u001b[0m\n",
      "\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m pd\u001b[39m.\u001b[39misna(inflation):\n",
      "\u001b[0;32m     27\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32m---> 28\u001b[0m last_n_periods \u001b[39m=\u001b[39m find_last_n_inflation_periods(inflation, date, \u001b[39m5\u001b[39;49m)\n",
      "\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m last_n_periods:\n",
      "\u001b[0;32m     30\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\n",
      "Cell \u001b[1;32mIn[103], line 11\u001b[0m, in \u001b[0;36mfind_last_n_inflation_periods\u001b[1;34m(inflation, date, n)\u001b[0m\n",
      "\u001b[0;32m      7\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[39mFinds the last n periods with the same inflation status as the current date.\u001b[39;00m\n",
      "\u001b[0;32m      9\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m     10\u001b[0m a \u001b[39m=\u001b[39m merged\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;32m---> 11\u001b[0m a \u001b[39m=\u001b[39m a[a[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m1947\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;32m     12\u001b[0m a \u001b[39m=\u001b[39m a[a[\u001b[39m'\u001b[39m\u001b[39mInflation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m inflation]\n",
      "\u001b[0;32m     13\u001b[0m a \u001b[39m=\u001b[39m a[a[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m date]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[0;32m   3494\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n",
      "\u001b[0;32m   3495\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n",
      "\u001b[1;32m-> 3496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n",
      "\u001b[0;32m   3498\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n",
      "\u001b[0;32m   3499\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "\u001b[0;32m   3500\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3551\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[0;32m   3549\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n",
      "\u001b[0;32m   3550\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n",
      "\u001b[0;32m   3708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n",
      "\u001b[0;32m   3709\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m   3710\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n",
      "\u001b[0;32m   3711\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   3714\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n",
      "\u001b[0;32m   3715\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n",
      "\u001b[0;32m   3717\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "\u001b[0;32m   3718\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   3699\u001b[0m nv\u001b[39m.\u001b[39mvalidate_take((), kwargs)\n",
      "\u001b[0;32m   3701\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "\u001b[1;32m-> 3703\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n",
      "\u001b[0;32m   3704\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n",
      "\u001b[0;32m   3705\u001b[0m )\n",
      "\u001b[0;32m   3706\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:900\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n",
      "\u001b[0;32m    897\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n",
      "\u001b[0;32m    899\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "\u001b[1;32m--> 900\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n",
      "\u001b[0;32m    901\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n",
      "\u001b[0;32m    902\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n",
      "\u001b[0;32m    903\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n",
      "\u001b[0;32m    904\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n",
      "\u001b[0;32m    905\u001b[0m     consolidate\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n",
      "\u001b[0;32m    906\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:692\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n",
      "\u001b[0;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n",
      "\u001b[0;32m    686\u001b[0m         indexer,\n",
      "\u001b[0;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n",
      "\u001b[0;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n",
      "\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n",
      "\u001b[0;32m    690\u001b[0m     )\n",
      "\u001b[0;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n",
      "\u001b[0;32m    693\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n",
      "\u001b[0;32m    694\u001b[0m             indexer,\n",
      "\u001b[0;32m    695\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n",
      "\u001b[0;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39m(\n",
      "\u001b[0;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m blk\u001b[39m.\u001b[39mfill_value\n",
      "\u001b[0;32m    698\u001b[0m             ),\n",
      "\u001b[0;32m    699\u001b[0m         )\n",
      "\u001b[0;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n",
      "\u001b[0;32m    701\u001b[0m     ]\n",
      "\u001b[0;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:693\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[0;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n",
      "\u001b[0;32m    686\u001b[0m         indexer,\n",
      "\u001b[0;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n",
      "\u001b[0;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n",
      "\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n",
      "\u001b[0;32m    690\u001b[0m     )\n",
      "\u001b[0;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n",
      "\u001b[1;32m--> 693\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n",
      "\u001b[0;32m    694\u001b[0m             indexer,\n",
      "\u001b[0;32m    695\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n",
      "\u001b[0;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n",
      "\u001b[0;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n",
      "\u001b[0;32m    698\u001b[0m             ),\n",
      "\u001b[0;32m    699\u001b[0m         )\n",
      "\u001b[0;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n",
      "\u001b[0;32m    701\u001b[0m     ]\n",
      "\u001b[0;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1137\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n",
      "\u001b[0;32m   1134\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m   1135\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m-> 1137\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n",
      "\u001b[0;32m   1138\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n",
      "\u001b[0;32m   1139\u001b[0m )\n",
      "\u001b[0;32m   1141\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n",
      "\u001b[0;32m   1142\u001b[0m \u001b[39m#  this assertion\u001b[39;00m\n",
      "\u001b[0;32m   1143\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m new_mgr_locs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n",
      "\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n",
      "\u001b[0;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n",
      "\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\prana\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:160\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n",
      "\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;32m--> 160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n",
      "\u001b[0;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n",
      "\u001b[0;32m    162\u001b[0m )\n",
      "\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flip_order:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#You have to run this in collab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_last_n_inflation_periods(inflation, date, n):\n",
    "    \"\"\"\n",
    "    Finds the last n periods with the same inflation status as the current date.\n",
    "    \"\"\"\n",
    "    a = merged.copy()\n",
    "    a = a[a['date'] > '1947']\n",
    "    a = a[a['Inflation'] == inflation]\n",
    "    a = a[a['date'] < date]\n",
    "    a = a.sort_values('date', ascending=False)\n",
    "    last_n_periods = a['date'].iloc[:n].tolist()\n",
    "    return last_n_periods\n",
    "\n",
    "\n",
    "grouped = merged.groupby(['Inflation', 'date'])\n",
    "total_returns = []\n",
    "\n",
    "# Calculate the top 10 and bottom 10 industries for each date\n",
    "for name, group in grouped:\n",
    "    date = name[1]\n",
    "    inflation = group['Inflation'].iloc[0]\n",
    "    if pd.isna(inflation):\n",
    "        continue\n",
    "    last_n_periods = find_last_n_inflation_periods(inflation, date, 5)\n",
    "    if not last_n_periods:\n",
    "        continue\n",
    "    inflation_group = merged[merged['date'].isin(last_n_periods) & (merged['Inflation'] == inflation)]\n",
    "    sorted_group = inflation_group.sort_values(\"MthRet\", ascending=False)\n",
    "    top_10 = list(sorted_group.head(10)['Industry Title'].unique())\n",
    "    bottom_10 = list(sorted_group[sorted_group[\"MthRet\"] < 0]['Industry Title'].unique()[:10])\n",
    "    top_10_industries = group[group['Industry Title'].isin(top_10)]\n",
    "    bottom_10_industries = group[group['Industry Title'].isin(bottom_10)]\n",
    "    top_10_return = np.mean(top_10_industries[\"MthRet\"])\n",
    "    bottom_10_return = np.mean(bottom_10_industries[\"MthRet\"])\n",
    "    total_return = top_10_return - bottom_10_return\n",
    "    total_returns.append(total_return)\n",
    "\n",
    "total_returns = [x for x in total_returns if not np.isnan(x)]\n",
    "average_total_return = np.mean(total_returns)\n",
    "\n",
    "average_total_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_returns = [x for x in total_returns if not np.isnan(x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002202447710998025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.mean(total_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_21912\\3893374852.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015863126089658244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = a.copy()\n",
    "# First, we need to calculate the market capitalization of each company in the dataset\n",
    "df['MthPrc'] = df['MthPrc'].str.replace(',','')\n",
    "df['ShrOut'] = df['ShrOut'].astype(float)\n",
    "df['MthPrc'] = df['MthPrc'].astype(float)\n",
    "df['MarketCap'] = df['ShrOut'] * df['MthPrc']\n",
    "\n",
    "# Next, we'll group the data by date and calculate the total market capitalization for each date\n",
    "grouped = df.groupby('date')\n",
    "total_market_cap = grouped['MarketCap'].sum()\n",
    "\n",
    "# Now we'll calculate the market weight of each company on each date by dividing its market capitalization by the total market capitalization\n",
    "df['MarketWeight'] = df.apply(lambda x: x['MarketCap']/total_market_cap[x['date']], axis=1)\n",
    "\n",
    "# Finally, we'll multiply the return of each company by its market weight and sum up the results to get the market weighted value portfolio return for each date\n",
    "df = df.dropna(subset=['MarketWeight', 'MthRet'])\n",
    "df['MarketWeightedReturn'] = df['MarketWeight'] * df['MthRet']\n",
    "\n",
    "market_weighted_return = df.groupby('date')['MarketWeightedReturn'].sum()\n",
    "\n",
    "market_weighted_return.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015863126089658244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group the data by date and get the monthly return for each industry\n",
    "grouped_by_date = a.groupby(\"MthCalDt\")\n",
    "\n",
    "# Create an empty list to store the monthly return for the top 10% of industries for each date\n",
    "monthly_return_top_10_percent = []\n",
    "\n",
    "# Iterate through each date group\n",
    "for date, date_group in grouped_by_date:\n",
    "    # Sort the date group by monthly return\n",
    "    date_group_sorted = date_group.sort_values(\"MthRet\", ascending=False)\n",
    "    \n",
    "    # Get the number of industries for this date group\n",
    "    n = len(date_group_sorted)\n",
    "    \n",
    "    # Get the top 10% of industries\n",
    "    top_10_percent = date_group_sorted.iloc[:int(n * 0.1)]\n",
    "    \n",
    "    # Calculate the average monthly return for the top 10% of industries\n",
    "    avg_monthly_return = top_10_percent[\"MthRet\"].mean()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    monthly_return_top_10_percent.append((date, avg_monthly_return))\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "monthly_return_top_10_percent_df = pd.DataFrame(monthly_return_top_10_percent, columns=[\"MthCalDt\", \"Avg_Monthly_Return\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2650357963888545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monthly_return_top_10_percent_df['Avg_Monthly_Return'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Group the data by date and get the monthly return for each industry\n",
    "grouped_by_date = a.groupby(\"MthCalDt\")\n",
    "\n",
    "# Create an empty list to store the weighted monthly return for the top 10% of industries for each date\n",
    "monthly_return_top_10_percent_weighted = []\n",
    "\n",
    "# Iterate through each date group\n",
    "for date, date_group in grouped_by_date:\n",
    "    # Sort the date group by monthly return\n",
    "    date_group_sorted = date_group.sort_values(\"MthRet\", ascending=False)\n",
    "    \n",
    "    # Get the number of industries for this date group\n",
    "    n = len(date_group_sorted)\n",
    "    \n",
    "    # Get the top 10% of industries\n",
    "    top_10_percent = date_group_sorted.iloc[:int(n * 0.1)]\n",
    "    \n",
    "    # Calculate the weighted monthly return for the top 10% of industries\n",
    "    weighted_monthly_return = (top_10_percent[\"MthRet\"] * top_10_percent[\"ShrOut\"]).sum() / top_10_percent[\"ShrOut\"].sum()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    monthly_return_top_10_percent_weighted.append((date, weighted_monthly_return))\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "monthly_return_top_10_percent_weighted_df = pd.DataFrame(monthly_return_top_10_percent_weighted, columns=[\"MthCalDt\", \"Weighted_Avg_Monthly_Return\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c754d8008c5f8560e4adf341ebf96f62d30db323e3ac43f60a1cb4dab6d757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
